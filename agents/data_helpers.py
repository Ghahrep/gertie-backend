# agents/data_helpers.py - Enhanced with Quick Wins
"""
Data Helpers for Agent-Backend Integration - Enhanced with Quick Wins
==================================================================

Added quick wins:
1. Enhanced confidence scoring with tool success weighting
2. Portfolio-specific tool selection
3. Context-aware quick actions generation
4. Professional response formatting
5. Intelligent error recovery
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
import logging

logger = logging.getLogger(__name__)

class AgentDataHelper:
    """Helper class for converting agent data to backend tool formats - Enhanced"""
    
    # QUICK WIN 1: Enhanced Confidence Scoring
    @staticmethod
    def calculate_enhanced_confidence(tool_results: List[Dict], base_confidence: float) -> int:
        """Calculate confidence based on tool success rates"""
        tool_success_weight = 0.0
        
        for result in tool_results:
            if result.get('success', True):
                tool_success_weight += 0.1  # Each successful tool adds 10%
            else:
                tool_success_weight -= 0.2  # Failed tools reduce confidence
        
        # Adjust base confidence by tool performance
        adjusted_confidence = base_confidence + (tool_success_weight * base_confidence)
        return int(min(99, max(60, adjusted_confidence)))  # Clamp between 60-99

    # QUICK WIN 2: Portfolio-Specific Tool Selection
    @staticmethod
    def select_tools_for_portfolio(portfolio_data: Dict, analysis_type: str) -> List[str]:
        """Select appropriate tools based on portfolio characteristics"""
        total_value = portfolio_data.get('total_value', 0)
        holdings_count = len(portfolio_data.get('holdings', []))
        
        tools = []
        
        # Portfolio size-based tool selection
        if total_value > 100000:  # Larger portfolios get institutional tools
            tools.extend(['advanced_monte_carlo_stress_test', 'calculate_regime_conditional_risk'])
        else:
            tools.extend(['calculate_risk_metrics', 'basic_stress_test'])
        
        # Holdings complexity-based selection
        if holdings_count > 5:
            tools.append('calculate_correlation_matrix')
            tools.append('calculate_dynamic_risk_budgets')
        
        # Analysis type specific tools
        if analysis_type == 'risk_analysis':
            tools.extend(['var_calculation', 'tail_risk_assessment'])
        elif analysis_type == 'optimization':
            tools.extend(['portfolio_optimization', 'rebalancing_analysis'])
        
        return tools

    # QUICK WIN 3: Context-Aware Quick Actions
    @staticmethod
    def generate_contextual_quick_actions(analysis_result: Dict, portfolio_data: Dict) -> List[Dict]:
        """Generate context-specific quick actions"""
        actions = []
        risk_score = analysis_result.get('analysis', {}).get('riskScore', 50)
        portfolio_value = portfolio_data.get('total_value', 0)
        
        # Risk-based actions
        if risk_score > 75:
            actions.append({
                "label": "ðŸš¨ Urgent: Risk Reduction Strategy",
                "action": "risk_reduction_plan",
                "agent": "portfolio_manager",
                "priority": "critical",
                "params": {"focus": "immediate_risk_mitigation"}
            })
        elif risk_score > 60:
            actions.append({
                "label": "âš¡ Risk Review & Optimization",
                "action": "risk_optimization",
                "agent": "quantitative_analyst", 
                "priority": "high"
            })
        
        # Portfolio size-based actions
        if portfolio_value > 250000:
            actions.append({
                "label": "ðŸ“Š Institutional Strategy Review",
                "action": "strategic_review",
                "agent": "cio",
                "priority": "medium"
            })
        
        # Analysis-specific actions
        content_lower = analysis_result.get('content', '').lower()
        if 'diversification' in content_lower:
            actions.append({
                "label": "ðŸŽ¯ Diversification Deep Dive",
                "action": "diversification_analysis",
                "agent": "portfolio_manager",
                "priority": "medium"
            })
        
        if 'stress' in content_lower or 'var' in content_lower:
            actions.append({
                "label": "ðŸ’ª Stress Test Analysis", 
                "action": "comprehensive_stress_test",
                "agent": "quantitative_analyst",
                "priority": "high"
            })
        
        return actions[:3]  # Limit to top 3 actions

    # QUICK WIN 4: Professional Response Formatting
    @staticmethod
    def format_professional_response(content: str, confidence: int, specialist: str, 
                                   risk_score: Optional[int] = None, 
                                   tool_performance: Optional[Dict] = None) -> str:
        """Add professional formatting with confidence indicators"""
        
        # Confidence indicator with color coding
        if confidence > 85:
            confidence_indicator = "ðŸŸ¢ High Confidence"
            confidence_desc = "Institutional-grade analysis"
        elif confidence > 70:
            confidence_indicator = "ðŸŸ¡ Moderate Confidence"
            confidence_desc = "Professional assessment"
        else:
            confidence_indicator = "ðŸ”´ Review Recommended"
            confidence_desc = "Preliminary analysis"
        
        # Risk level indicator
        risk_indicator = ""
        if risk_score is not None:
            if risk_score > 75:
                risk_indicator = "\n*Risk Level: ðŸ”´ HIGH - Immediate attention required*"
            elif risk_score > 50:
                risk_indicator = "\n*Risk Level: ðŸŸ¡ MODERATE - Monitor closely*"
            else:
                risk_indicator = "\n*Risk Level: ðŸŸ¢ LOW - Well managed*"
        
        # Tool performance indicator
        tool_indicator = ""
        if tool_performance:
            tools_used = tool_performance.get('tools_count', 0)
            success_rate = tool_performance.get('success_rate', 1.0) * 100
            tool_indicator = f"\n*Analysis powered by {tools_used} institutional tools ({success_rate:.0f}% success rate)*"
        
        formatted_content = f"""**{specialist.replace('_', ' ').title()} Analysis**

*{confidence_indicator} ({confidence}%) â€¢ {confidence_desc}*{risk_indicator}

{content}

{tool_indicator}
---
*Analysis timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*"""
        
        return formatted_content

    # QUICK WIN 5: Intelligent Error Recovery
    @staticmethod
    def enhanced_error_response(error_message: str, portfolio_data: Dict, 
                              attempted_tools: List[str], specialist: str) -> Dict[str, Any]:
        """Generate intelligent error recovery response"""
        portfolio_value = portfolio_data.get('total_value', 0)
        holdings_count = len(portfolio_data.get('holdings', []))
        
        # Generate context-appropriate fallback analysis
        fallback_insights = []
        
        if portfolio_value > 0:
            fallback_insights.append(f"Based on your portfolio value of {AgentDataHelper.format_currency(portfolio_value)}")
        
        if holdings_count > 0:
            if holdings_count >= 5:
                fallback_insights.append("your diversified portfolio structure suggests moderate risk management")
            else:
                fallback_insights.append("your concentrated portfolio may benefit from additional diversification")
        
        # Tool-specific recovery suggestions
        recovery_suggestions = []
        if 'var_calculation' in attempted_tools:
            recovery_suggestions.append("Consider implementing systematic risk monitoring")
        if 'portfolio_optimization' in attempted_tools:
            recovery_suggestions.append("Regular portfolio review recommended")
        if 'stress_test' in attempted_tools:
            recovery_suggestions.append("Monitor portfolio resilience during market volatility")
        
        # Default suggestions if no specific tools
        if not recovery_suggestions:
            if portfolio_value > 100000:
                recovery_suggestions.append("Consider professional portfolio review")
            recovery_suggestions.append("Maintain diversification across asset classes")
        
        return {
            "specialist": specialist,
            "analysis_type": "error_recovery",
            "content": f"**{specialist.replace('_', ' ').title()} - Analysis Recovery**\n\nWhile experiencing technical difficulties with advanced tools, I can provide initial guidance:\n\n{' '.join(fallback_insights)}.\n\n**Immediate Recommendations:**\n" + "\n".join(f"â€¢ {suggestion}" for suggestion in recovery_suggestions) + f"\n\n**Technical Note:** Attempted {len(attempted_tools)} analytical tools. System will retry with simplified analysis approach.",
            "analysis": {
                "riskScore": 50,  # Neutral when uncertain
                "recommendation": "Retry analysis or consult multiple specialists",
                "confidence": 65,  # Lower confidence due to tool failure
                "specialist": specialist.replace('_', ' ').title()
            },
            "metadata": {
                "recovery_mode": True,
                "attempted_tools": attempted_tools,
                "fallback_analysis": True,
                "error_type": "tool_execution_failure"
            }
        }

    # EXISTING METHODS (keeping all your current functionality)
    
    @staticmethod
    def extract_portfolio_returns(portfolio_data: Dict, lookback_days: int = 252) -> pd.Series:
        """
        Extract portfolio-level returns series from portfolio data
        """
        try:
            # Extract portfolio info
            total_value = portfolio_data.get("total_value", 100000)
            holdings = portfolio_data.get("holdings", [])
            daily_change_str = portfolio_data.get("daily_change", "0%")
            
            # Parse daily change
            try:
                daily_change = float(daily_change_str.replace("%", "").replace("+", "")) / 100
            except:
                daily_change = 0.0
            
            # Generate realistic return series based on portfolio characteristics
            return AgentDataHelper._generate_portfolio_returns(
                total_value, len(holdings), daily_change, lookback_days
            )
            
        except Exception as e:
            logger.error(f"Error extracting portfolio returns: {e}")
            # Fallback to simple random series
            return AgentDataHelper._generate_fallback_returns(lookback_days)
    
    @staticmethod
    def convert_portfolio_to_dataframe(portfolio_data: Dict, lookback_days: int = 252) -> pd.DataFrame:
        """Convert portfolio context to multi-asset returns DataFrame"""
        try:
            holdings = portfolio_data.get("holdings", [])
            
            if not holdings:
                # Create single-asset DataFrame if no holdings
                portfolio_returns = AgentDataHelper.extract_portfolio_returns(portfolio_data, lookback_days)
                return pd.DataFrame({'Portfolio': portfolio_returns})
            
            # Generate returns for each holding
            dates = pd.date_range(end=datetime.now(), periods=lookback_days, freq='D')
            returns_data = {}
            
            for holding in holdings:
                ticker = holding.get("ticker", holding.get("symbol", f"ASSET_{len(returns_data)}"))
                weight = holding.get("weight", 1.0 / len(holdings))
                
                # Generate correlated returns for this asset
                asset_returns = AgentDataHelper._generate_asset_returns(
                    ticker, weight, lookback_days
                )
                returns_data[ticker] = asset_returns
            
            return pd.DataFrame(returns_data, index=dates)
            
        except Exception as e:
            logger.error(f"Error converting portfolio to DataFrame: {e}")
            # Fallback to single portfolio series
            portfolio_returns = AgentDataHelper.extract_portfolio_returns(portfolio_data, lookback_days)
            return pd.DataFrame({'Portfolio': portfolio_returns})
    
    @staticmethod
    def extract_portfolio_weights(portfolio_data: Dict) -> pd.Series:
        """Extract current portfolio weights from portfolio data"""
        try:
            holdings = portfolio_data.get("holdings", [])
            total_value = portfolio_data.get("total_value", 100000)
            
            if not holdings or total_value == 0:
                return pd.Series(dtype=float)
            
            weights = {}
            for holding in holdings:
                ticker = holding.get("ticker", holding.get("symbol", f"ASSET_{len(weights)}"))
                value = holding.get("value", 0) or holding.get("market_value", 0)
                weight = value / total_value if total_value > 0 else 0
                weights[ticker] = weight
            
            return pd.Series(weights)
            
        except Exception as e:
            logger.error(f"Error extracting portfolio weights: {e}")
            return pd.Series(dtype=float)
    
    @staticmethod
    def create_factor_data(lookback_days: int = 252) -> pd.DataFrame:
        """Create factor data for factor risk attribution analysis"""
        try:
            dates = pd.date_range(end=datetime.now(), periods=lookback_days, freq='D')
            
            # Generate realistic factor returns
            np.random.seed(42)  # For reproducible results
            
            # Market factor (higher volatility)
            market = np.random.normal(0.0008, 0.012, lookback_days)
            
            # Value factor (lower correlation with market)
            value = np.random.normal(0.0002, 0.008, lookback_days)
            
            # Growth factor (correlated with market)
            growth_base = np.random.normal(0.0003, 0.010, lookback_days)
            growth = 0.6 * market + 0.4 * growth_base
            
            # Size factor (small cap premium)
            size = np.random.normal(0.0001, 0.009, lookback_days)
            
            # Quality factor (defensive)
            quality = np.random.normal(0.0004, 0.006, lookback_days)
            
            factor_data = pd.DataFrame({
                'Market': market,
                'Value': value,
                'Growth': growth,
                'Size': size,
                'Quality': quality
            }, index=dates)
            
            return factor_data
            
        except Exception as e:
            logger.error(f"Error creating factor data: {e}")
            # Return minimal factor data
            dates = pd.date_range(end=datetime.now(), periods=lookback_days, freq='D')
            return pd.DataFrame({'Market': np.random.normal(0, 0.01, lookback_days)}, index=dates)
    
    @staticmethod
    def format_currency(amount: float) -> str:
        """Format currency amounts for display"""
        if abs(amount) >= 1_000_000:
            return f"${amount/1_000_000:.1f}M"
        elif abs(amount) >= 1_000:
            return f"${amount/1_000:.0f}K"
        else:
            return f"${amount:.0f}"
    
    @staticmethod
    def format_percentage(value: float, decimals: int = 1) -> str:
        """Format percentage values for display"""
        return f"{value * 100:.{decimals}f}%"
    
    @staticmethod
    def extract_chat_history(context: Dict) -> List[Dict[str, str]]:
        """Extract chat history in format expected by behavioral tools"""
        try:
            chat_history = context.get("conversation_history", [])
            if not chat_history:
                return []
            
            # Convert to behavioral tools format
            formatted_history = []
            for message in chat_history:
                if isinstance(message, dict):
                    role = message.get("role", "user")
                    content = message.get("content", message.get("message", ""))
                    if content:
                        formatted_history.append({"role": role, "content": content})
            
            return formatted_history
            
        except Exception as e:
            logger.error(f"Error extracting chat history: {e}")
            return []
    
    # Private helper methods
    
    @staticmethod
    def _generate_portfolio_returns(total_value: float, holdings_count: int, 
                                  daily_change: float, lookback_days: int) -> pd.Series:
        """Generate realistic portfolio returns based on characteristics"""
        
        # Base volatility based on portfolio characteristics
        if holdings_count >= 8:
            base_vol = 0.012  # Well diversified
        elif holdings_count >= 4:
            base_vol = 0.016  # Moderately diversified
        else:
            base_vol = 0.022  # Concentrated
        
        # Adjust volatility based on portfolio size
        if total_value > 500000:
            vol_adjustment = 0.9  # Larger portfolios often less volatile
        elif total_value > 100000:
            vol_adjustment = 1.0
        else:
            vol_adjustment = 1.1  # Smaller portfolios more volatile
        
        final_vol = base_vol * vol_adjustment
        
        # Generate return series
        np.random.seed(42)  # Reproducible for testing
        returns = np.random.normal(0.0005, final_vol, lookback_days)
        
        # Incorporate today's performance
        if abs(daily_change) > 0.001:  # If meaningful daily change
            returns[-1] = daily_change
        
        # Create time series
        dates = pd.date_range(end=datetime.now(), periods=lookback_days, freq='D')
        return pd.Series(returns, index=dates, name='Portfolio')
    
    @staticmethod
    def _generate_asset_returns(ticker: str, weight: float, lookback_days: int) -> np.array:
        """Generate returns for individual asset"""
        
        # Use ticker hash for consistent but different seeds
        seed = abs(hash(ticker)) % 10000
        np.random.seed(seed)
        
        # Asset-specific characteristics
        if any(tech in ticker.upper() for tech in ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'NVDA']):
            # Tech stocks - higher volatility
            mean_return = 0.0008
            volatility = 0.025
        elif any(util in ticker.upper() for util in ['PG', 'JNJ', 'KO', 'PEP']):
            # Defensive stocks - lower volatility
            mean_return = 0.0004
            volatility = 0.012
        else:
            # Default characteristics
            mean_return = 0.0006
            volatility = 0.018
        
        return np.random.normal(mean_return, volatility, lookback_days)
    
    @staticmethod
    def _generate_fallback_returns(lookback_days: int) -> pd.Series:
        """Generate fallback return series when data extraction fails"""
        dates = pd.date_range(end=datetime.now(), periods=lookback_days, freq='D')
        returns = np.random.normal(0.0005, 0.015, lookback_days)
        return pd.Series(returns, index=dates, name='Portfolio')


# Enhanced integrator classes with quick wins

class RiskAnalysisIntegrator:
    """Integrator for risk analysis between agents and backend tools - Enhanced"""
    
    @staticmethod
    def get_comprehensive_risk_analysis(portfolio_data: Dict) -> Dict:
        """Enhanced comprehensive risk analysis with tool performance tracking"""
        tool_results = []
        start_time = datetime.now()
        
        try:
            from tools.risk_tools import (
                calculate_risk_metrics,
                calculate_regime_conditional_risk,
                advanced_monte_carlo_stress_test,
                calculate_time_varying_risk
            )
            
            # Extract portfolio returns
            portfolio_returns = AgentDataHelper.extract_portfolio_returns(portfolio_data)
            
            # Track each tool execution
            try:
                risk_metrics = calculate_risk_metrics(portfolio_returns)
                tool_results.append({"tool": "calculate_risk_metrics", "success": True})
            except Exception as e:
                logger.error(f"Risk metrics calculation failed: {e}")
                tool_results.append({"tool": "calculate_risk_metrics", "success": False})
                risk_metrics = {}
            
            try:
                regime_risk = calculate_regime_conditional_risk(portfolio_returns)
                tool_results.append({"tool": "calculate_regime_conditional_risk", "success": True})
            except Exception as e:
                logger.error(f"Regime risk calculation failed: {e}")
                tool_results.append({"tool": "calculate_regime_conditional_risk", "success": False})
                regime_risk = {}
            
            try:
                stress_results = advanced_monte_carlo_stress_test(
                    portfolio_returns, num_scenarios=1000, time_horizon=30
                )
                tool_results.append({"tool": "advanced_monte_carlo_stress_test", "success": True})
            except Exception as e:
                logger.error(f"Stress test failed: {e}")
                tool_results.append({"tool": "advanced_monte_carlo_stress_test", "success": False})
                stress_results = {}
            
            try:
                time_varying_risk = calculate_time_varying_risk(portfolio_returns)
                tool_results.append({"tool": "calculate_time_varying_risk", "success": True})
            except Exception as e:
                logger.error(f"Time-varying risk calculation failed: {e}")
                tool_results.append({"tool": "calculate_time_varying_risk", "success": False})
                time_varying_risk = {}
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            return {
                'basic_risk': risk_metrics,
                'regime_risk': regime_risk,
                'stress_test': stress_results,
                'time_varying': time_varying_risk,
                'portfolio_value': portfolio_data.get('total_value', 0),
                'tool_performance': {
                    'tools_used': len(tool_results),
                    'success_rate': sum(1 for r in tool_results if r['success']) / len(tool_results),
                    'execution_time': execution_time,
                    'tool_results': tool_results
                }
            }
            
        except Exception as e:
            logger.error(f"Error in comprehensive risk analysis: {e}")
            return {
                'error': str(e),
                'tool_performance': {
                    'tools_used': len(tool_results),
                    'success_rate': 0,
                    'execution_time': (datetime.now() - start_time).total_seconds(),
                    'tool_results': tool_results
                }
            }


class StrategyAnalysisIntegrator:
    """Integrator for strategy analysis between agents and backend tools - Enhanced"""
    
    @staticmethod
    def get_portfolio_optimization_analysis(portfolio_data: Dict) -> Dict:
        """Enhanced portfolio optimization analysis with tool tracking"""
        tool_results = []
        start_time = datetime.now()
        
        try:
            from tools.risk_tools import calculate_dynamic_risk_budgets
            from tools.strategy_tools import design_risk_adjusted_momentum_strategy
            
            # Convert portfolio data
            returns_df = AgentDataHelper.convert_portfolio_to_dataframe(portfolio_data)
            current_weights = AgentDataHelper.extract_portfolio_weights(portfolio_data)
            
            # Dynamic risk budgeting
            risk_budget_results = None
            if len(current_weights) > 0:
                try:
                    risk_budget_results = calculate_dynamic_risk_budgets(
                        returns_df, current_weights
                    )
                    tool_results.append({"tool": "calculate_dynamic_risk_budgets", "success": True})
                except Exception as e:
                    logger.error(f"Risk budgeting failed: {e}")
                    tool_results.append({"tool": "calculate_dynamic_risk_budgets", "success": False})
            
            # Strategy analysis
            try:
                prices_df = (1 + returns_df).cumprod() * 100  # Convert to price series
                strategy_results = design_risk_adjusted_momentum_strategy(
                    prices_df, returns_df, lookback_days=60
                )
                tool_results.append({"tool": "design_risk_adjusted_momentum_strategy", "success": True})
            except Exception as e:
                logger.error(f"Strategy analysis failed: {e}")
                tool_results.append({"tool": "design_risk_adjusted_momentum_strategy", "success": False})
                strategy_results = {}
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            return {
                'risk_budgeting': risk_budget_results,
                'strategy_analysis': strategy_results,
                'current_weights': current_weights,
                'portfolio_value': portfolio_data.get('total_value', 0),
                'tool_performance': {
                    'tools_used': len(tool_results),
                    'success_rate': sum(1 for r in tool_results if r['success']) / len(tool_results) if tool_results else 0,
                    'execution_time': execution_time,
                    'tool_results': tool_results
                }
            }
            
        except Exception as e:
            logger.error(f"Error in strategy analysis: {e}")
            return {
                'error': str(e),
                'tool_performance': {
                    'tools_used': len(tool_results),
                    'success_rate': 0,
                    'execution_time': (datetime.now() - start_time).total_seconds(),
                    'tool_results': tool_results
                }
            }


class BehavioralAnalysisIntegrator:
    """Integrator for behavioral analysis between agents and backend tools - Enhanced"""
    
    @staticmethod
    def get_behavioral_analysis(query: str, context: Dict, portfolio_data: Dict) -> Dict:
        """Enhanced behavioral analysis with tool tracking"""
        tool_results = []
        start_time = datetime.now()
        
        try:
            from tools.behavioral_tools import analyze_chat_for_biases, detect_market_sentiment
            
            # Extract chat history
            chat_history = AgentDataHelper.extract_chat_history(context)
            
            # Add current query to history
            if query:
                chat_history.append({"role": "user", "content": query})
            
            # Bias analysis
            try:
                bias_results = analyze_chat_for_biases(chat_history)
                tool_results.append({"tool": "analyze_chat_for_biases", "success": True})
            except Exception as e:
                logger.error(f"Bias analysis failed: {e}")
                tool_results.append({"tool": "analyze_chat_for_biases", "success": False})
                bias_results = {}
            
            # Sentiment analysis
            try:
                sentiment_results = detect_market_sentiment(chat_history)
                tool_results.append({"tool": "detect_market_sentiment", "success": True})
            except Exception as e:
                logger.error(f"Sentiment analysis failed: {e}")
                tool_results.append({"tool": "detect_market_sentiment", "success": False})
                sentiment_results = {}
            
            # Portfolio context for risk assessment
            portfolio_returns = AgentDataHelper.extract_portfolio_returns(portfolio_data)
            
            execution_time = (datetime.now() - start_time).total_seconds()
            
            return {
                'bias_analysis': bias_results,
                'sentiment_analysis': sentiment_results,
                'portfolio_context': {
                    'total_value': portfolio_data.get('total_value', 0),
                    'holdings_count': len(portfolio_data.get('holdings', [])),
                    'daily_change': portfolio_data.get('daily_change', '0%')
                },
                'portfolio_returns': portfolio_returns,
                'tool_performance': {
                    'tools_used': len(tool_results),
                    'success_rate': sum(1 for r in tool_results if r['success']) / len(tool_results) if tool_results else 0,
                    'execution_time': execution_time,
                    'tool_results': tool_results
                }
            }
            
        except Exception as e:
            logger.error(f"Error in behavioral analysis: {e}")
            return {
                'error': str(e),
                'tool_performance': {
                    'tools_used': len(tool_results),
                    'success_rate': 0,
                    'execution_time': (datetime.now() - start_time).total_seconds(),
                    'tool_results': tool_results
                }
            }


# Enhanced convenience functions with quick wins

def get_real_var_analysis(portfolio_data: Dict) -> Tuple[float, float, str]:
    """Get real VaR analysis for quantitative agent - Enhanced with confidence tracking"""
    try:
        analysis = RiskAnalysisIntegrator.get_comprehensive_risk_analysis(portfolio_data)
        
        if 'error' in analysis:
            return -0.025, -0.045, "Moderate"  # Fallback values
        
        basic_risk = analysis.get('basic_risk', {})
        risk_measures = basic_risk.get('risk_measures', {})
        
        var_95 = risk_measures.get('95%', {}).get('var', -0.025)
        var_99 = risk_measures.get('99%', {}).get('var', -0.045)
        
        # Determine risk level with enhanced logic
        tool_performance = analysis.get('tool_performance', {})
        success_rate = tool_performance.get('success_rate', 1.0)
        
        # Adjust confidence based on tool success
        if success_rate < 0.8:
            risk_level = "Uncertain"
        elif abs(var_95) > 0.03:
            risk_level = "High"
        elif abs(var_95) > 0.015:
            risk_level = "Moderate"
        else:
            risk_level = "Low"
        
        return var_95, var_99, risk_level
        
    except Exception as e:
        logger.error(f"Error getting VaR analysis: {e}")
        return -0.025, -0.045, "Moderate"


def get_real_stress_test_results(portfolio_data: Dict) -> Dict:
    """Get real stress test results for quantitative agent - Enhanced"""
    try:
        analysis = RiskAnalysisIntegrator.get_comprehensive_risk_analysis(portfolio_data)
        
        if 'error' in analysis:
            return {'error': analysis['error']}
        
        stress_results = analysis.get('stress_test', {})
        tool_performance = analysis.get('tool_performance', {})
        
        # Add tool performance metadata
        stress_results['tool_performance'] = tool_performance
        
        return stress_results
        
    except Exception as e:
        logger.error(f"Error getting stress test results: {e}")
        return {'error': str(e)}


def get_real_optimization_results(portfolio_data: Dict) -> Dict:
    """Get real optimization results for portfolio manager - Enhanced"""
    try:
        analysis = StrategyAnalysisIntegrator.get_portfolio_optimization_analysis(portfolio_data)
        return analysis
        
    except Exception as e:
        logger.error(f"Error getting optimization results: {e}")
        return {'error': str(e)}


def get_regime_analysis(portfolio_data: Dict) -> Dict:
    """Get regime analysis for CIO agent - Enhanced with tool tracking"""
    tool_results = []
    start_time = datetime.now()
    
    try:
        from tools.regime_tools import detect_hmm_regimes, detect_volatility_regimes
        
        portfolio_returns = AgentDataHelper.extract_portfolio_returns(portfolio_data)
        
        # HMM regime detection
        try:
            hmm_result = detect_hmm_regimes(portfolio_returns)
            tool_results.append({"tool": "detect_hmm_regimes", "success": True})
        except Exception as e:
            logger.error(f"HMM regime detection failed: {e}")
            tool_results.append({"tool": "detect_hmm_regimes", "success": False})
            hmm_result = {}
        
        # Volatility regime detection
        try:
            vol_result = detect_volatility_regimes(portfolio_returns)
            tool_results.append({"tool": "detect_volatility_regimes", "success": True})
        except Exception as e:
            logger.error(f"Volatility regime detection failed: {e}")
            tool_results.append({"tool": "detect_volatility_regimes", "success": False})
            vol_result = {}
        
        execution_time = (datetime.now() - start_time).total_seconds()
        
        return {
            'hmm_regimes': hmm_result,
            'volatility_regimes': vol_result,
            'tool_performance': {
                'tools_used': len(tool_results),
                'success_rate': sum(1 for r in tool_results if r['success']) / len(tool_results) if tool_results else 0,
                'execution_time': execution_time,
                'tool_results': tool_results
            }
        }
        
    except Exception as e:
        logger.error(f"Error getting regime analysis: {e}")
        return {
            'error': str(e),
            'tool_performance': {
                'tools_used': len(tool_results),
                'success_rate': 0,
                'execution_time': (datetime.now() - start_time).total_seconds(),
                'tool_results': tool_results
            }
        }